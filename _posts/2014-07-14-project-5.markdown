---
layout: default
modal-id: 8
title: 3D-Bin-Packing
short-caption: 3D-Bin-Packing
date: 2024-3-1
img: packing.gif
alt: image-alt
project-date: 2024-3-1
category: Computer Vision, Manipulation, NP-hard
github: https://github.com/JihaiZhao/RRT
description: <p style="text-align:left;">This project uses the Franka Emika Panda arm to solve a 3D bin packing problem which is an optimization challenge that involves efficiently packing a set of items of different sizes into a container, while minimizing wasted space and maximizing space utilization. It uses computer vision to detect the dimension and location of the object needed to be packed, and it uses Moveit2 to plan the trajectories.</p><br><h4><strong>Video Demo</strong></h4><iframe width="700" height="450" src="https://www.youtube.com/embed/YN1Lk3Jp5u0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><br><h4><strong>Object Detection</strong></h4><p style="text-align:left;">Detecting the dimension of the object and finding the precise location of the project are the keys in this project. A realsense D435 is mounted on the robot. The object was detected and tracked using the RGB camera data and depth data provided by the Intel RealSense camera. All potential objects are a red color, and their location is determined using color masking in OpenCV to isolate the red pixels in the camera’s view. A contour was drawn around the red area, and the centroid of the contour and four more points on the edges were found. Then the grasp position and orientation of the object were found. </br>The object will be placed on the “bin” and the robot will move to the observe position first. Once the camera detects an object appears, the robot will move to the top of the object to make sure the object is at the center of the camera to better detect the dimension of the object.</p> <img class="img-responsive" src="img/PACKING/1.png" alt="profile-pic" /><br><h4><strong>Grasping</strong></h4><p style="text-align:left;">In order to finish grasping/placing process accurately and reliably every time, a custom gripper was designed, as well as the shape of the objects. <br>The grasping process include 3 steps<li>Move to the observe position</li><li>Move to the checking position (camera is on the top of the object)</li><li>Move to the actual position of the object and grasp it.</li>A custom wrapper interface was used in controlling the robot during both grasping and placing. The purpose of the wrapper interface was to make implantation easier; it offers a simpler way of planning trajectories. The wrapper was write in <a href= "https://github.com/JihaiZhao/Botrista" >Making Pour Over Coffee with a Robot Arm</a> project</p></br></br></br></br>
---