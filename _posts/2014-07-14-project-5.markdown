---
layout: default
modal-id: 8
title: 3D-Bin-Packing
short-caption: 3D-Bin-Packing
date: 2024-3-1
img: packing.gif
alt: image-alt
project-date: 2024-3-1
category: Computer Vision, Manipulation, NP-hard
github: https://github.com/JihaiZhao/Winter-project
description: <p style="text-align:left;">This project uses the Franka Emika Panda arm to solve a 3D bin packing problem which is an optimization challenge that involves efficiently packing a set of items of different sizes into a container, while minimizing wasted space and maximizing space utilization. It uses computer vision to detect the dimension and location of the object needed to be packed, and it uses Moveit2 to plan the trajectories.</p><br><h4><strong>Video Demo</strong></h4><iframe width="700" height="450" src="https://www.youtube.com/embed/YN1Lk3Jp5u0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><br><h4><strong>Object Detection</strong></h4><p style="text-align:left;">Detecting the dimension of the object and finding the precise location of the project are the keys in this project. A realsense D435 is mounted on the robot. The object was detected and tracked using the RGB camera data and depth data provided by the Intel RealSense camera. All potential objects are a red color, and their location is determined using color masking in OpenCV to isolate the red pixels in the camera’s view. A contour was drawn around the red area, and the centroid of the contour and four more points on the edges were found. Then the grasp position and orientation of the object were found. </br>The object will be placed on the “bin” and the robot will move to the observe position first. Once the camera detects an object appears, the robot will move to the top of the object to make sure the object is at the center of the camera to better detect the dimension of the object.</p> <img class="img-responsive" src="img/PACKING/1.png" alt="profile-pic" /><br><h4><strong>Grasping</strong></h4><p style="text-align:left;">In order to finish grasping/placing process accurately and reliably every time, a custom gripper was designed, as well as the shape of the objects. <br>The grasping process include 3 steps</p><li><p style="text-align:left;">Move to the observe position</p></li><li><p style="text-align:left;">Move to the checking position (camera is on the top of the object)</p></li><li><p style="text-align:left;">Move to the actual position of the object and grasp it.</p></li><p style="text-align:left;">A custom wrapper interface was used in controlling the robot during both grasping and placing. The purpose of the wrapper interface was to make implantation easier; it offers a simpler way of planning trajectories. The wrapper was write in <a href= "https://github.com/JihaiZhao/Botrista" >Making Pour Over Coffee with a Robot Arm</a> project</p></br><h4><strong>Packing</strong></h4><p style="text-align:left;">For this project, Best-fit algorithm was used to solve this 3D rectangular packing problem. Its input is a list of items of different sizes, the output the the location of the item to place. The best-fit algorithm uses the following heuristic<span>:</span></p><li><p style="text-align:left;">It keeps a list of open bins, which is initially empty. </p></li><li><p style="text-align:left;">When an item arrives, it finds the bin with the maximum load into which the item can fit, if any. The load of a bin is defined as the sum of sizes of existing items in the bin before placing the new item. </p></li><p style="text-align:left;"></p><img class="img-responsive" src="img/PACKING/pack_py.gif" alt="profile-pic" />
---