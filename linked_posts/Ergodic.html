<html >
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="css/posts.css">
    <head>
        <title>Ergodic Imitation with 7-DoF Franka Arm</title>
    </head>

    <nav class="navbar">
        <a href="/.."><i class="fa fa-home" ></i></a>
    </nav>  

    <style>
        /* Remove default padding and margin for ul */
        ul {
            width: 80%; /* Set width */
            margin: auto; /* Center align ul */
            padding-left: 0; /* Remove left padding */
        }
        /* Add left margin to li for alignment with <p> */
        li {
            margin-left: 20px; /* Adjust spacing as needed */
        }
    </style>
    

    <body>
        <h4><strong>Overview</strong></h4>
        <p>
            The purpose of this project is to leverage <strong>ergodic imitation</strong> to learn both desirable and undesirable behaviors. 
            To facilitate effective data collection, I first implemented an <strong>impedance control mode</strong> for a 7-DoF collaborative robotic arm 
            (Franka) in collaboration with Courtney. Subsequently, I developed a <strong>haptic-guided teleoperation</strong> system for the Franka robot. 
            This system enables the user to control <strong>Franka 1</strong>, which operates in impedance control mode, and couples its movements to 
            <strong>Franka 2</strong>, such that any motion of Franka 1 is mirrored by Franka 2.
        </p>
        <p>
            Following this, I employed a <strong>learning-from-demonstration (LfD)</strong> approach to derive robust task definitions from a combination 
            of positive and negative demonstrations. The algorithmic framework for task learning is based on the <strong>ergodic metric</strong>, a measure 
            of the information content in motion. Finally, I demonstrated the efficacy of this learning approach on (.......) using the 7-DoF Franka arm.
        </p>        
        <h4><strong>Video Demo</strong></h4>
        <!-- <iframe width="600" height="450" src="https://www.youtube.com/embed/q7HbfBILOt4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
         -->
        
        <br>
        <h4>Impedance Control</h4>
        <p>Allow user to interact with the robot arm and feel wightless when moving the arm</p>
        <p>Talk about the equipment we used, the hardware, three different impedance modes we implemented, the graphs of comparison, and our conclusion.</p>

        <br>
    
        <h4>Haptic-Guided Teleoperation</h4>
        <p>As the baseline setup, we implemented a position-based uni-
            lateral PD controller to control the slave motion via the master.
            This baseline implementation realizes teleoperation to move the
            slave arm, however, no feedback is provided at the master side.
            For this reason, we call this baseline the “No Feedback” condi-
            tion.
        </p>
        <p>
            Force Feedback Using Joint Angle Coupling
        </p>
        <br>
        <p>show equations and graphs</p>
    
        <h4>Density Map</h4>
        <p>
            Collecting data using haptic-guided teleoperation. Remember the location of the points, 
            (give positive/negative labels) using k-means to do clustering. Find the center of each cluster and generate probability density function </p>
    
        <h4>Ergodic Search</h4>
        <p>
            it can be considered as an optimal control problem. The iterative linear quadratic regular (iLQR) algorithm 
            follows a gradient descent approach to find a locally optimal solution. 
            Given the current estimation of the control  u(t) , at each iteration, iLQR finds the descent direction  v(t)  by solving the following ODEs:
            
            For the ergodic controller,
            we model the system as a double-integrator with state X =
            [x, y, ẋ, ẏ] and U = [ẍ, ÿ].
        </p>

        <h4>Robot Arm Testing</h4>
        <p>
            Get trajectory from ergodic search and use moveit to control the robot.
            test I finished: reaching a target location without colliding with an obstacle.
            cleaning task: success m is evaluated as a continuous variable
            based on both workspace coverage and object avoidance
            balance task: 
        </p>
    </body>
    </html>