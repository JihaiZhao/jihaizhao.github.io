<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"
    integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="css/posts.css">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<head>
    <title>Ergodic Imitation with 7-DoF Franka Arm</title>
</head>

<nav class="navbar">
    <a href="/.."><i class="fa fa-home"></i></a>
</nav>

<style>
    ul {
        width: 80%;
        margin: auto;
        padding-left: 0;
        font-size: 18px;
    }

    li {
        margin-left: 20px;
        font-size: 18px;
    }
</style>

<body>
    <h1 class='title'>Ergodic Imitation with 7-DoF Franka Arm</h1>

    <hr class="para-break" data-content="  Video Demo  ">

    <hr class="para-break" data-content="  Overview  " id="intro">
    <p>
        The purpose of this project is to leverage <strong>ergodic imitation</strong> to learn both desirable and
        undesirable behaviors. To facilitate effective data collection, I first implemented an <strong>impedance control
            mode</strong> for a
        7-DoF collaborative robotic arm (Franka) in collaboration with Courtney. Subsequently, I developed a
        <strong>haptic-guided
            teleoperation</strong> system for the Franka robot. This system enables the user to control <strong>Franka
            1</strong>, which operates in impedance control mode, and couples its movements to <strong>Franka
            2</strong>, such that any motion of Franka 1 is mirrored by Franka 2.
    </p>
    <p>
        Following this, I employed a <strong>learning-from-demonstration (LfD)</strong> approach to derive robust task
        definitions from a combination of positive and negative demonstrations. The algorithmic framework for task
        learning is based on the
        <strong>ergodic metric</strong>, a measure of the information content in motion. Finally, I demonstrated the
        efficacy of this learning approach on (.......) using the 7-DoF Franka arm.
    </p>

    <br>

    <hr class="para-break" data-content="  Haptic-Guided Teleoperation  ">
    <p>
        For the hardware, I used two Franka Emika Robot. As the baseline setup, I first implemented the “No Feedback”
        condition which is direct joint-position coupling
        to control the slave robot motion via the master robot. To control the Franka Robot, I used <a
            href="https://frankaemika.github.io/docs/libfranka.html" target="_blank">libfranka library</a>, which is a
        C++ library provided by Franka. For the master robot, I used the impedance control mode I implemented before
        (more details can be found in this post). For the slave robot, I used a control loop in the libfranka model
        library. This control loop includes two Callback functions for sending joint-level torque commands and target
        joint positions. The torque command was computed from the joint impedance control law, and the target joint
        positions were received from the master Franka robot. For the communication between the master and slave robot,
        I used ROS2 subscription and publisher to share the JointState information.
    </p>
    <img src="../img/ergodic/no_feedback.png" style="width:80%">

    <br>
    <p>
        To ensure better teleoperation performance, I added Force Feedback. The calculated torque from the slave robot
        keeps publishing and is received by the master robot. Then the torque on the master robot is a combination of
        impedance control and the torque reading.
    </p>
    <img src="../img/ergodic/force_feedback.png" style="width:80%">

    <hr class="para-break" data-content="  Density Map  ">
    <p>
        Collecting data using haptic-guided teleoperation. Remember the location of the points, assign positive/negative
        labels using k-means clustering, and find the center of each cluster to generate a probability density function.
    </p>

    <p>
        \[
        X = [0, L_1] \times \cdots \times [0, L_d],
        \]
    </p>

    <p>
        where \( L_i \) is the boundary length of the \( i \)-th dimension. The normalized Fourier basis function is
        defined over the search space. Denote a state within the search space as \( x = [x_1, \dots, x_d] \in X \), the
        normalized Fourier basis function is characterized by a \( d \)-dimensional index vector \( k = [k_1, \dots,
        k_d] \), where each entry of the vector is a whole number \( k_i \in [0, 1, 2, \dots, K] \):
    </p>

    <p>
        \[
        f_k(x) = \frac{1}{h_k} \prod_{i=1}^{d} \cos\left( \frac{k_i \pi}{L_i} x_i \right),
        \]
    </p>

    <p>
        where \( h_k \) is the normalization term, ensuring the function space norm of each basis function \( \left[
        \int_{\mathcal{X}} f_k(x)^2 dx \right]^{\frac{1}{2}} \) is 1.
    </p>

    <p>
        The normalized basis functions consist of a set of *orthonormal bases* in the infinite dimensional function
        space. Thus, we can transform any function with the same domain (the search space) into a set of new coordinates
        under these *orthonormal bases*.
    </p>

    <p>
        Given a spatial probability density function \( p(x) \), we can transform this function as follows:
    </p>

    <p>
        \[
        p(x) = \sum_{k=1}^{\infty} \left( \underbrace{\int_{\mathcal{X}} p(x) f_k(x) dx}_{\phi_k} \right) \cdot f_k(x)
        = \sum_{k=1}^{\infty} \phi_k \cdot f_k(x),
        \]
    </p>

    <p>
        where all the coefficients \( [\phi_k] \) consist of the coordinates of the function \( p(x) \) under the bases
        \( [f_k(x)] \).
    </p>

    <p>
        Though the equality only holds in theory when we have an infinite number of basis functions, in practice, we can
        choose a finite number of basis functions to approximate an infinite-dimensional function \( p(x) \) within a
        finite-dimensional Euclidean space (a finite number of coefficients).
    </p>

    <p>
        This transformation from an infinite-dimensional function space to a finite-dimensional vector space is crucial
        for the ergodic metric. We now verify this transformation below.
    </p>

    <div class="container">
        <div class="row">
            <div class="col-lg-2">
            </div>
            <div class="col-lg-4">
                <img src="../img/ergodic/data.png" style="width:80%">
            </div>
            <div class="col-lg-4">
                <img src="../img/ergodic/pdf.png" style="width:80%">
            </div>
        </div>
    </div>

    <hr class="para-break" data-content="  Ergodic Search  ">
    <p>
        It can be considered as an optimal control problem. The iterative linear quadratic regular (iLQR) algorithm
        follows a gradient descent approach to find a locally optimal solution. Given the current estimation of the
        control \( u(t) \), at each iteration, iLQR finds the descent direction \( v(t) \) by solving the following
        ODEs:
    </p>


    <p>The standard formula for the optimal control problem is:</p>

    <div class="equation">
        <p>u<sup>*</sup>(t) s.t. = argmin<sub>u(t)</sub> &int;<sub>0</sub><sup>T</sup> l(x(t), u(t)) dt + m(x(T))</p>
        <p>x˙(t) = f(x(t), u(t)), x(0) = x<sub>0</sub></p>
    </div>

    <p>The iterative Linear Quadratic Regulator (iLQR) algorithm follows a gradient descent approach to find a locally
        optimal solution. Given the current estimation of the control u(t), at each iteration, iLQR finds the descent
        direction v(t) by solving the following ODEs:</p>

    <div class="equation">
        <p>B(t)<sup>&#8594;</sup>p(t) + b(t) + R<sup>&#8594;</sup>v(t) = 0</p>
        <p>p˙(t) = −A(t)<sup>&#8594;</sup>p(t) − a(t) − Q<sup>&#8594;</sup>z(t)</p>
        <p>z˙(t) = A(t)z(t) + B(t)v(t)</p>
    </div>

    <p>The initial and terminal conditions are:</p>
    <div class="equation">
        <p>z(0) = 0, p(T) = dd<sub>x</sub> m(x(T))</p>
    </div>

    <p>Where:</p>
    <div class="equation">
        <p>A(t), B(t), a(t), b(t) = dd<sub>x</sub> f(x(t), u(t)) = dd<sub>u</sub> f(x(t), u(t)) = dd<sub>x</sub> l(x(t),
            u(t)) = dd<sub>u</sub> l(x(t), u(t))</p>
    </div>

    <p>And Q<sub>z</sub> and R<sub>v</sub> are user-defined regularization parameters.</p>

    <p>
        For the ergodic controller, we model the system as a double-integrator with state \( X = [x, y, \dot{x},
        \dot{y}] \) and \( U = [\ddot{x}, \ddot{y}]. \)
    </p>
    <img src="../img/ergodic/ergodic.png" style="width:80%">

    <hr class="para-break" data-content="  Robot Arm Testing  ">
    <p>
        Get trajectory from ergodic search and use MoveIt to control the robot. Tests completed include reaching a
        target location without colliding with an obstacle. For the cleaning task, success is evaluated as a continuous
        variable based on both workspace coverage and object avoidance. For the balance task:
    </p>

    <hr class="para-break" data-content="  Related Links  ">
    <p>
        <a href="https://ieeexplore.ieee.org/document/8979376" target="_blank">Haptic-Guided Teleoperation of a 7-DoF
            Collaborative Robot Arm With an Identical Twin Master</a>
        <a href="https://ergodiccontrol.github.io/" target="_blank">ICRA 2024 Ergodic Control Workshop</a>
        <a href="https://ieeexplore.ieee.org/document/9561746" target="_blank">Ergodic imitation: Learning from what to
            do and what not to do</a>

    </p>

</body>

</html>