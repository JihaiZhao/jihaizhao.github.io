<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="css/posts.css">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Robot Captures Purple Pen</title>
    </head>

    <nav class="navbar">
        <a href="/.."><i class="fa fa-home" ></i></a>
    </nav>  

    <style>
        /* Remove default padding and margin for ul */
        ul {
            width: 80%; /* Set width */
            margin: auto; /* Center align ul */
            padding-left: 0; /* Remove left padding */
        }
        /* Add left margin to li for alignment with <p> */
        li {
            margin-left: 20px; /* Adjust spacing as needed */
        }
    </style>

    <body style="font-family: Arial, sans-serif; line-height: 1.6; margin: 20px;">
        <h4><strong>Overview</strong></h4>
        <p>Use the RealSense to measure the 3D location of my purple pen. I use the interbotix_xs_toolbox to control the robot. Finally, get the robot capturing the pen.</p>

        <h4><strong>Video Demo</strong></h4>
        <iframe 
            width="700" 
            height="450" 
            src="https://www.youtube.com/embed/zqDcZX2BYwI" 
            title="YouTube video player" 
            frameborder="0" 
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
            allowfullscreen>
        </iframe>
        <br>

        <h4><strong>Set Up</strong></h4>
        <p>
            The physical setup for this project requires the Trossen PincherX 100 and the Intel RealSense D435i. 
            The field of view of the RealSense should substantially overlap with part of the PincherX's workspace, and I decided 
            to offset the D435i 90 degrees from the front of the PincherX.
        </p>

        <h4><strong>Pen Recognition</strong></h4>
        <p>
            The approach is to use classical computer vision techniques on the RGB image to locate the pen in 2D space. 
            Then align the Depth map to the RGB image and use the pen location as a mask to get the 3D information. 
            Finally, draw the contour of the pen and find the centroid of the pen. This information will be fed into a controller 
            that will enable the robot to grab the pen.
        </p>
        <br>

        <h4><strong>Robot Control</strong></h4>
        <p>
            I will use the interbotix_xs_toolbox to control the robot. 
            There are a total of four steps:
        </p>
        <ul>
            <li>Measure the pen location.</li>
            <li>Move forward until the pen is inside the grippers.</li>
            <li>Close the gripper.</li>
            <li>Return to home position.</li>
        </ul>
    </body>
</html>
